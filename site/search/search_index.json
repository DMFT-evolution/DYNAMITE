{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DMFE: Dynamical Mean-Field Evolution Toolkit","text":"<p>DMFE solves non-stationary dynamical mean-field equations for glassy and related systems with GPU acceleration and a validated CPU path. It targets expert users in statistical physics, condensed matter, and machine learning working with aging dynamics and DMFT-like closures.</p>"},{"location":"#problem-setting-dmft-aging-quench","title":"Problem setting (DMFT, aging, quench)","text":"<p>We evolve correlation and response functions after a quench under closed dynamical equations of the form</p> \\[ \\partial_t C(t,t') = \\mathcal{F}[C,R](t,t')\\,,\\qquad \\partial_t R(t,t') = \\mathcal{G}[C,R](t,t')\\,,\\quad t\\ge t'\\,. \\] <p>The solver implements a numerical renormalization scheme with two-dimensional interpolation, reducing the asymptotic cost from cubic to sublinear in simulated time while controlling accuracy relevant to aging observables.</p>"},{"location":"#method-at-a-glance","title":"Method at a glance","text":"<ul> <li>Two-dimensional sparse interpolation for history terms</li> <li>Adaptive RK54 as default; auto-switch to SSPRK104 at stability limit; optional SERK2 trials after sparsification</li> <li>GPU kernels with portable CPU fallback</li> <li>Asynchronous I/O; resume runs and version-compat checks</li> </ul> <p>Relevant modules: core, EOMs, interpolation, convolution, sparsify, simulation, io.</p>"},{"location":"#quickstart-expert","title":"Quickstart (expert)","text":"<ul> <li>Build Release:</li> </ul> <pre><code>./build.sh\n</code></pre> <ul> <li>Short quench on L=512 grid:</li> </ul> <pre><code>./RG-Evo -L 512 -l 0.5 -m 1e4 -D false\n</code></pre> <ul> <li>Outputs: HDF5 <code>data.h5</code> when available (datasets: <code>QKv</code>, <code>QRv</code>, <code>dQKv</code>, <code>dQRv</code>, <code>t1grid</code>, <code>rvec</code>, <code>drvec</code>) with attributes for parameters and time; otherwise binary with text summaries.</li> </ul>"},{"location":"#where-to-go-next","title":"Where to go next","text":"<ul> <li>Installation notes: install.md (toolchain/CUDA arch selection)</li> <li>Usage and flags: usage.md (physics meanings and recommended ranges)</li> <li>Equations and observables: concepts/eoms-and-observables.md</li> <li>Architecture and accuracy controls: concepts/*</li> <li>API reference (headers): reference/api/</li> </ul>"},{"location":"install/","title":"Install &amp; Build","text":"<p>DMFE builds with CMake for CPU and optionally CUDA GPUs.</p>"},{"location":"install/#prerequisites","title":"Prerequisites","text":"<ul> <li>CMake &gt;= 3.24</li> <li>A C++17 compiler (GCC or Clang). OpenMP recommended.</li> <li>Optional: CUDA Toolkit (for GPU build)</li> <li>Optional: HDF5 dev libs (for compile-time HDF5 linkage)</li> </ul>"},{"location":"install/#build-from-source","title":"Build from source","text":"<p>Recommended:</p> <pre><code>./build.sh\n</code></pre> <p>Manual:</p> <pre><code>cmake -S . -B build\ncmake --build build -j $(nproc)\n</code></pre> <p>Executables: <code>./RG-Evo</code> (and optionally <code>./RG-Evo-shared</code>).</p>"},{"location":"install/#options","title":"Options","text":"<ul> <li><code>-DDMFE_DEBUG=ON</code> \u2014 device debug flags, thrust checks</li> <li><code>-DDMFE_PORTABLE_BUILD=ON</code> \u2014 no <code>-march=native</code>, shared cudart</li> <li><code>-DCMAKE_CUDA_ARCHITECTURES=\"80;86;90\"</code> \u2014 SM list</li> <li><code>-DUSE_HDF5=ON</code> \u2014 compile-time HDF5</li> <li><code>-DUSE_HDF5_RUNTIME=OFF</code> \u2014 disable runtime-optional HDF5 wrapper</li> </ul> <p>See README Build options for the full list and examples.</p>"},{"location":"install/#cuda-notes","title":"CUDA notes","text":"<ul> <li>If CUDA is installed and a compiler is detected, CUDA is enabled by default.</li> <li>For mixed GCC/CUDA versions, prefer <code>clang++-14</code> as host for nvcc or use GCC 11/12.</li> <li>For clusters, use <code>-DDMFE_PORTABLE_BUILD=ON</code> and set a single SM: <code>-DCMAKE_CUDA_ARCHITECTURES=80</code>.</li> </ul>"},{"location":"install/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>CMake can\u2019t find CUDA: set <code>-DDMFE_WITH_CUDA=OFF</code> to build CPU-only; verify <code>nvcc --version</code>.</li> <li>Linker errors with libgomp/libomp: set <code>-DDMFE_STATIC_OPENMP=OFF</code> or install matching OpenMP.</li> <li>Runtime: missing grid data \u2192 ensure <code>Grid_data/&lt;L&gt;/</code> exists for your <code>-L</code>.</li> </ul>"},{"location":"usage/","title":"Usage","text":"<p>Entry point: <code>./RG-Evo</code>. Show all options with <code>-h</code>.</p>"},{"location":"usage/#model-and-parameters","title":"Model and parameters","text":"<ul> <li><code>-p</code>, <code>-q</code> (integers): model orders (e.g., spherical mixed p-spin). Use <code>p&gt;=2</code>; common: <code>p=3, q=4</code>.</li> <li><code>-l, --lambda</code> (float): coupling strength (dimensionless). Typical 0.1\u20131; study transitions by sweeping.</li> <li><code>-T, --T0</code> (float|inf): initial/thermal scale; use <code>inf</code> for zero-noise quenches.</li> <li><code>-G, --Gamma</code> (float): damping or mass-like scale where applicable.</li> </ul> <p>Note: At present, the mixed spherical p-spin equations are hardcoded as in the paper; other models are not yet configurable. This will be relaxed in a future release.</p>"},{"location":"usage/#discretization-and-accuracy","title":"Discretization and accuracy","text":"<ul> <li><code>-L</code> grid length: selects <code>Grid_data/&lt;L&gt;/</code> (available: 512/1024/2048). Larger L \u2192 higher accuracy and cost.</li> <li><code>-m</code> max iterations and <code>-t</code> max physical time bound the run. For exploratory runs, start with <code>-m 1e4</code>.</li> <li><code>-d</code> minimum time step and <code>-e</code> error tolerance control adaptivity (RK54 default with auto-switch to SSPRK104; SERK2 trials optional). Smaller <code>-e</code> \u2192 better accuracy.</li> </ul>"},{"location":"usage/#execution-controls","title":"Execution controls","text":"<ul> <li><code>-g, --gpu</code> boolean: enable GPU kernels (default true when available); set <code>false</code> for CPU-only or reproducibility.</li> <li><code>-A, --async-export</code> boolean: asynchronous I/O to avoid blocking the integrator (default true).</li> <li><code>-s</code> save outputs (default true) and <code>-o</code> output directory root.</li> <li><code>-D</code> debug logging; <code>-v</code> print build/version; <code>-I</code> allow resume across incompatible versions (use with care).</li> </ul>"},{"location":"usage/#inputs-grids","title":"Inputs (grids)","text":"<p>Interpolation weights/indices are loaded from <code>Grid_data/&lt;L&gt;/</code>: - <code>theta.dat</code>, <code>phi1.dat</code>, <code>phi2.dat</code>, <code>int.dat</code> - <code>posA1y.dat</code>, <code>posA2y.dat</code>, <code>posB2y.dat</code> - <code>indsA1y.dat</code>, <code>indsA2y.dat</code>, <code>indsB2y.dat</code> - <code>weightsA1y.dat</code>, <code>weightsA2y.dat</code>, <code>weightsB2y.dat</code></p> <p>Choose the largest L that fits memory/time for your study; verify convergence of observables with L.</p>"},{"location":"usage/#outputs-and-observables","title":"Outputs and observables","text":"<ul> <li>HDF5 <code>data.h5</code> when available; else <code>data.bin</code> plus text summaries.</li> <li>Datasets: <code>QKv</code>, <code>QRv</code>, <code>dQKv</code>, <code>dQRv</code>, <code>t1grid</code>, <code>rvec</code>, <code>drvec</code> (see concepts/eoms-and-observables.md).</li> <li>Text: <code>params.txt</code>, <code>correlation.txt</code>, <code>energy.txt</code>, <code>rvec.txt</code>, <code>qk0.txt</code>.</li> </ul> <p>Resume: automatic if a compatible checkpoint is found (version policy documented in concepts/version-compatibility.md).</p>"},{"location":"usage/#typical-runs","title":"Typical runs","text":"<ul> <li>Short aging run (GPU): <pre><code>./RG-Evo -L 512 -l 0.5 -m 1e4 -D false\n</code></pre></li> <li>CPU-only reproducibility: <pre><code>./RG-Evo --gpu false -L 512 -l 0.5 -m 5e3\n</code></pre></li> <li>Parameter sweep in \u03bb around a transition: <pre><code>for lam in 0.4 0.5 0.6; do ./RG-Evo -L 1024 -l \"$lam\" -m 2e4 -D false; done\n</code></pre></li> </ul>"},{"location":"concepts/algorithm/","title":"Algorithm (from Lang\u2013Sachdev\u2013Diehl, arXiv:2504.06849)","text":"<p>This section summarizes the numerical renormalization algorithm implemented in DMFE for solving non-stationary dynamical mean-field equations (DMFT) after a quench.</p>"},{"location":"concepts/algorithm/#dynamical-equations","title":"Dynamical equations","text":"<p>We evolve correlation C(t,t') and response R(t,t') for t \u2265 t'. The equations take the schematic form</p> \\[ \\partial_t C(t,t') = \\mathcal{F}[C,R](t,t')\\,,\\qquad \\partial_t R(t,t') = \\mathcal{G}[C,R](t,t')\\,. \\] <p>For the spherical mixed p-spin model (representative), the functionals \\(\\mathcal{F},\\mathcal{G}\\) contain convolution-like memory integrals in both time arguments with kernels determined by the interaction orders and couplings. The renormalization scheme reorganizes these integrals to achieve sublinear scaling in simulated time.</p>"},{"location":"concepts/algorithm/#numerical-renormalization-core-idea","title":"Numerical renormalization: core idea","text":"<ul> <li>Represent the 2D time plane on an adaptive sparse grid with nested blocks.</li> <li>Interleave time evolution with periodic sparsification to prune redundant history while preserving interpolation accuracy.</li> <li>Maintain a compressed representation of C and R enabling fast convolution-like updates via precomputed index/weight maps.</li> </ul> <p>This reduces the asymptotic cost from \\(\\mathcal{O}(T^3)\\) to sublinear in the total simulated time (see paper for precise exponents and regimes), enabling orders-of-magnitude longer runs.</p> <p>Important: DMFE uses exactly the non-equidistant, nested grid defined in the arXiv paper. The performance gains critically rely on this grid; substituting an equidistant grid typically destroys sublinear scaling. See Interpolation grids for details.</p>"},{"location":"concepts/algorithm/#discrete-scheme-and-data-layout","title":"Discrete scheme and data layout","text":"<ul> <li>Store fields on a sparse set of (t, t') nodes; the diagonal t=t' is tracked separately for observables.</li> <li>Precompute interpolation structures (positions, indices, weights) on a base grid of length L; these are used for fast 2D interpolation.</li> <li>History is organized in layers corresponding to renormalized time scales; layers can be coarsened as t grows while keeping error below a tolerance.</li> </ul> <p>Symbols in outputs: - <code>QKv</code>, <code>QRv</code>: grid samples of C and R - <code>dQKv</code>, <code>dQRv</code>: their time derivatives - <code>t1grid</code>: time nodes used by the integrator - <code>rvec</code>, <code>drvec</code>: reduced observables along the diagonal</p>"},{"location":"concepts/algorithm/#integrator-and-update-cycle","title":"Integrator and update cycle","text":"<p>Time stepping follows the adaptive RK54 default and automatically switches to SSPRK104 once RK54 approaches its stability limit. After each sparsification, the code may attempt SERK2 (can be disabled via CLI). One step:</p> <ol> <li>Propose \\(\\Delta t\\) from local error control (tolerance <code>-e</code>, min step <code>-d</code>).</li> <li>Interpolate required history slices for convolution terms using precomputed indices and weights.</li> <li>Evaluate \\(\\mathcal{F},\\mathcal{G}\\) to obtain \\(\\partial_t C, \\partial_t R\\).</li> <li>Advance to t+\\(\\Delta t\\) with the active integrator (RK54 or SSPRK104; SERK2 when trialed after sparsify); update diagonal quantities.</li> <li>If pruning is due, sparsify history with a criterion ensuring interpolation error below target.</li> </ol>"},{"location":"concepts/algorithm/#pseudocode","title":"Pseudocode","text":"<pre><code>Initialize grids and data (C, R) at t = 0\nwhile t &lt; t_max and steps &lt; m_max:\n  dt &lt;- propose_step(tolerance=e, min_step=d)\n  H &lt;- interpolate_history(C, R, t, dt, structures=L)\n  dC, dR &lt;- EOMs(H, params)\n  C_next, R_next &lt;- step_active_integrator(C, R, dC, dR, dt)\n  update_diagonal_observables(C_next, R_next)\n  if sparsify_due(t):\n    C, R &lt;- sparsify(C_next, R_next, criterion)\n  else:\n    C, R &lt;- C_next, R_next\n  save_if_needed()\n  t &lt;- t + dt\n</code></pre>"},{"location":"concepts/algorithm/#error-control-and-accuracy","title":"Error control and accuracy","text":"<ul> <li>Local truncation error is controlled via <code>-e</code>; monitor step-size independence of observables.</li> <li>Sparsification ensures interpolation error is bounded; validate by short runs with sparsification off or conservative thresholds.</li> <li>Convergence in L (512/1024/2048) must be checked for quantities of interest, especially near transitions.</li> </ul>"},{"location":"concepts/algorithm/#complexity-and-performance","title":"Complexity and performance","text":"<p>The nested sparse representation amortizes the cost of memory integrals, leading to sublinear growth with simulated time. GPU kernels accelerate interpolation and convolution; CPU fallback preserves portability. Asynchronous I/O decouples storage from integration.</p>"},{"location":"concepts/algorithm/#references","title":"References","text":"<ul> <li>J. Lang, S. Sachdev, M. Diehl, \u201cNumerical renormalization of glassy dynamics,\u201d arXiv:2504.06849.</li> </ul>"},{"location":"concepts/algorithm/#see-also","title":"See also","text":"<ul> <li>EOMs and Observables: eoms-and-observables.md</li> <li>Time Integration: time-integration.md</li> </ul>"},{"location":"concepts/architecture/","title":"Architecture","text":"<p>The code mirrors physics operations:</p> <ul> <li>EOMs (<code>include/EOMs/</code>): RK54 (adaptive) with auto-switch to SSPRK104; optional SERK2 trials post-sparsification.</li> <li>Interpolation (<code>include/interpolation/</code>): sparse 2D interpolation kernels and index maps.</li> <li>Convolution (<code>include/convolution/</code>): memory-kernel evaluations.</li> <li>Sparsification (<code>include/sparsify/</code>): maintains sublinear memory/compute with error control.</li> <li>Simulation (<code>include/simulation/</code>): orchestration, checkpoints, and async I/O.</li> <li>Core/Math/IO/Version: utilities, numeric primitives, I/O (HDF5 runtime), version policy.</li> </ul> <p>Accuracy knobs:</p> <ul> <li>Grid length L (512/1024/2048): convergence in observables vs. runtime.</li> <li>Integrator tolerance <code>-e</code>, min step <code>-d</code>: trade accuracy vs. cost.</li> <li>Sparsification mode: aggressive vs. conservative.</li> </ul> <p>GPU/CPU paths are interchangeable; ensure convergence checks are done on your platform of choice.</p>"},{"location":"concepts/eoms-and-observables/","title":"Equations of motion (current model) and observables","text":"<p>We evolve correlation C(t,t') and response R(t,t') after a quench on the non-equidistant grid. Currently, DMFE has the mixed spherical p-spin equations hardcoded, matching the definitions in Lang\u2013Sachdev\u2013Diehl (arXiv:2504.06849). Generalization to pluggable models is planned.</p>"},{"location":"concepts/eoms-and-observables/#mixed-spherical-p-spin-eoms-paper-definitions","title":"Mixed spherical p-spin EOMs (paper definitions)","text":"<p>Let the memory kernels be functionals of C and R with p- and q-body terms and spherical constraint enforced via a Lagrange multiplier \u00b5(t). The equations read schematically</p> \\[ \\begin{aligned} \\partial_t C(t,t') &amp;= -\\mu(t)\\, C(t,t') \\\\ &amp;\\quad+ \\int_0^t ds\\, \\Sigma(t,s)\\, C(s,t') \\\\ &amp;\\quad+ \\int_0^{t'} ds\\, D(t,s)\\, R(t',s), \\\\ \\partial_t R(t,t') &amp;= -\\mu(t)\\, R(t,t') + \\delta(t-t') \\\\ &amp;\\quad+ \\int_{t'}^t ds\\, \\Sigma(t,s)\\, R(s,t'), \\end{aligned} \\] <p>with model-specific kernels (for a representative mixed p,q case) of the form</p> \\[ \\begin{aligned} \\Sigma(t,s) &amp;= p\\,J_p^2\\, C(t,s)^{p-1} R(t,s) \\\\ &amp;\\quad+ q\\,J_q^2\\, C(t,s)^{q-1} R(t,s), \\\\ D(t,s) &amp;= p\\,J_p^2\\, C(t,s)^{p-1} C(t,s) \\\\ &amp;\\quad+ q\\,J_q^2\\, C(t,s)^{q-1} C(t,s), \\end{aligned} \\] <p>and the spherical constraint fixing \u00b5(t) from C(t,t)=1. The concrete prefactors and any thermal/noise terms follow the arXiv paper\u2019s conventions; DMFE implements those definitions directly.</p> <p>Notes: - The exact expressions and units match the paper; see source under <code>include/EOMs/</code> for the hardcoded operators used at runtime. - The non-stationary (aging) regime requires both time integrals and thus benefits from the sparse 2D grid and renormalized history.</p>"},{"location":"concepts/eoms-and-observables/#stored-fields","title":"Stored fields","text":"<ul> <li><code>QKv</code>, <code>QRv</code>: discretized correlation/response on the sparse grid</li> <li><code>dQKv</code>, <code>dQRv</code>: time derivatives</li> <li><code>t1grid</code>: time grid values used by the integrator</li> <li><code>rvec</code>, <code>drvec</code>: reduced observables stored along the diagonal</li> </ul> <p>See <code>include/EOMs/*</code> and <code>include/interpolation/*</code> for algorithmic details.</p>"},{"location":"concepts/interpolation-grids/","title":"Interpolation grids (paper-defined, non\u2011equidistant)","text":"<p>DMFE uses exactly the non\u2011equidistant, nested time grid defined in Lang\u2013Sachdev\u2013Diehl (arXiv:2504.06849). The grid is multi\u2011scale and highly non\u2011uniform by design to resolve short\u2011time singular structure and long\u2011time aging simultaneously. All node locations and quadrature data are precomputed and shipped under <code>Grid_data/&lt;L&gt;/</code> for L \u2208 {512, 1024, 2048}.</p> <p>Why this matters: The algorithm\u2019s sublinear scaling depends critically on this grid. Although not extremely sensitive to tiny details, using a highly non\u2011equidistant grid with nested blocks is essential; equidistant grids defeat the renormalization gains and dramatically increase cost.</p>"},{"location":"concepts/interpolation-grids/#explicit-equations-as-in-arxiv250406849","title":"Explicit equations (as in arXiv:2504.06849)","text":"<p>We parametrize the two\u2011point functions on the triangular domain \\(t_2 \\le t_1\\) by the time ratio \\(\\phi = t_2/t_1 \\in [0,1]\\), i.e.</p> \\[ \\mathcal G(t_1,\\phi) \\equiv G(t_1,\\phi\\,t_1). \\] <p>The fixed irregular grid \\(\\{\\phi_k\\}_{k=1}^L\\) (dense near \\(0\\) and \\(1\\)) is given by the supplemental Eq. (S1):</p> \\[ \\xi_k = \\frac{2k - 1 - L}{L - 1},\\quad k=1,\\dots,L,\\qquad \\sigma_0 = -\\,W\\!\\left(-\\frac{1}{t_{\\max}}\\right), \\] <p>and the monotone arctan\u2011based mapping</p> \\[ \\phi_k = \\frac{\\arctan(\\sigma_\\infty) - \\arctan(\\sigma_\\infty - \\sigma_0\\,\\xi_k)}{\\arctan(\\sigma_\\infty) - \\arctan(\\sigma_\\infty - \\sigma_0)}. \\] <p>Here \\(\\sigma_\\infty\\) is a large positive constant that fixes end\u2011point crowding; any choice that yields sufficient density near \\(0\\) and \\(1\\) for your \\(t_{\\max}\\) is acceptable. This mapping is analytically invertible and yields near\u2011endpoint spacings that satisfy the resolution condition (paper Eq. (2)).</p> <p>For memory integrals (paper Eq. (3)), two contour families on the same grid are used:</p> \\[ \\rho_k^{(1)}(\\alpha_j) = \\phi_k\\,\\alpha_j,\\qquad \\rho_k^{(2)}(\\alpha_j) = \\alpha_j + (1-\\alpha_j)\\,\\phi_k,\\qquad \\alpha_j \\equiv \\phi_j. \\] <p>These generate the \u201cmixed\u201d directions required by the convolution structure and define the 2D interpolation stencils used at runtime.</p> <p>DMFE uses the following notation in code and data:</p> <ul> <li>\\(\\theta \\equiv \\{\\phi_k\\}\\) (stored in <code>theta.dat</code>).</li> <li>\\(\\varphi^{(1)} \\equiv \\{\\rho_k^{(1)}(\\alpha_j)\\}\\) (stored in <code>phi1.dat</code>).</li> <li>\\(\\varphi^{(2)} \\equiv \\{\\rho_k^{(2)}(\\alpha_j)\\}\\) (stored in <code>phi2.dat</code>).</li> <li>Quintic\u2011spline quadrature weights for the irregular grid (stored in <code>int.dat</code>).</li> </ul>"},{"location":"concepts/interpolation-grids/#what-the-files-contain","title":"What the files contain","text":"<ul> <li><code>theta.dat</code>  \u2014 primary (monotone) parameterization \u03b8 of time\u2011ratio nodes {\u03c6_k}.</li> <li><code>phi1.dat</code>, <code>phi2.dat</code> \u2014 the two contour families \u03d5\u00b9, \u03d5\u00b2 evaluated on the \u03c6\u2011grid; used to assemble 2D interpolation stencils consistent with the renormalized layering.</li> <li><code>int.dat</code> \u2014 quadrature weights associated with {\u03c6_k} for accurate evaluation of memory integrals.</li> <li><code>posA1y.dat</code>, <code>posA2y.dat</code>, <code>posB2y.dat</code> \u2014 physical positions of interpolation stencils assembled from \u03b8, \u03d5\u00b9, \u03d5\u00b2 (A/B families correspond to distinct directional stencils).</li> <li><code>indsA1y.dat</code>, <code>indsA2y.dat</code>, <code>indsB2y.dat</code> \u2014 index maps into the base arrays (C, R, and their derivatives) for fast gathers.</li> <li><code>weightsA1y.dat</code>, <code>weightsA2y.dat</code>, <code>weightsB2y.dat</code> \u2014 interpolation weights matching the index maps.</li> </ul> <p>These datasets jointly define the exact nodes and interpolation/quadrature rules used at runtime; they are identical to those used in the paper\u2019s benchmarks.</p>"},{"location":"concepts/interpolation-grids/#performance-note","title":"Performance note","text":"<p>Using these paper\u2011defined non\u2011equidistant grids is the primary reason the method attains sublinear growth of cost with simulated time. Changing to an equidistant grid will typically increase complexity toward the cubic baseline and should be avoided.</p>"},{"location":"concepts/interpolation-grids/#choosing-l-and-checking-convergence","title":"Choosing L and checking convergence","text":"<ul> <li>Available L: 512 / 1024 / 2048. Larger L \u2192 higher fidelity at higher cost.</li> <li>Validate by comparing observables (energy(t), C(t,t), C(t, \u03b1 t)) across L.</li> <li>Near phase transitions, prefer larger L to capture critical scaling.</li> </ul> <p>Inputs directory structure:</p> <ul> <li><code>Grid_data/&lt;L&gt;/theta.dat</code>, <code>phi1.dat</code>, <code>phi2.dat</code>, <code>int.dat</code></li> <li><code>Grid_data/&lt;L&gt;/posA1y.dat</code>, <code>posA2y.dat</code>, <code>posB2y.dat</code></li> <li><code>Grid_data/&lt;L&gt;/indsA1y.dat</code>, <code>indsA2y.dat</code>, <code>indsB2y.dat</code></li> <li><code>Grid_data/&lt;L&gt;/weightsA1y.dat</code>, <code>weightsA2y.dat</code>, <code>weightsB2y.dat</code></li> </ul>"},{"location":"concepts/interpolation-grids/#conceptual-figure-triangular-time-domain-and-nonequidistant-grid","title":"Conceptual figure: triangular time domain and non\u2011equidistant grid","text":"Triangular time domain with dense and sparse grid regions. <p>Only the triangular domain t' \u2264 t is simulated; points are dense at both short times (near the origin) and along the diagonal at long times (where the correlation length R grows like R(\u03c4) with \u03c4 = t - t'), with a sparse intermediate region where R ~ 1/t. This multi-scale structure reflects the renormalized layering that enables sublinear algorithmic scaling.</p>"},{"location":"concepts/sparsification/","title":"Sparsification","text":"<p>Sparsification preserves asymptotic efficiency by pruning history with controlled error. The pruning criterion and reconstruction exactly match the implementation in <code>src/sparsify/</code>.</p> <p>What is pruned: interior time\u2011nodes of the 1D history grid <code>t1grid</code> along \\(t_1\\). Endpoints are always kept.</p> <p>Pruning criterion (CPU and GPU): for each interior i \u2265 2 with i + 1 &lt; N, compute a smoothness measure using QK, QR and their t\u2011derivatives on the stencil {i\u22122, i\u22121, i, i+1} with non\u2011uniform gaps \u0394t:</p> <ul> <li>Let \\(t_{\\text{left}} = t[i-2],\\; t_{\\text{mid}} = t[i]\\); define \\(\\Delta_1 = t[i-1] - t_{\\text{left}},\\; \\Delta_2 = t_{\\text{mid}} - t_{\\text{left}},\\; \\Delta_3 = t[i+1] - t_{\\text{mid}}\\) and scale \\(s = \\Delta_2/12\\).</li> <li> <p>For each component \\(j = 1\\dots \\text{len}\\), accumulate</p> <p>\\(\\displaystyle s\\,\\big\\lvert 2\\,(QK[i]-QK[i-2]) - \\Delta_2\\,\\big(\\tfrac{\\mathrm d QK[i-1]}{\\Delta_1} + \\tfrac{\\mathrm d QK[i+1]}{\\Delta_3}\\big) \\big\\rvert\\)</p> <p>\\(\\displaystyle +\\; s\\,\\big\\lvert 2\\,(QR[i]-QR[i-2]) - \\Delta_2\\,\\big(\\tfrac{\\mathrm d QR[i-1]}{\\Delta_1} + \\tfrac{\\mathrm d QR[i+1]}{\\Delta_3}\\big) \\big\\rvert.\\)</p> </li> <li> <p>Optionally (CPU path), add the same form for the scalar \\(r\\):</p> <p>\\(\\displaystyle s\\,\\big\\lvert 2\\,(r[i]-r[i-2]) - \\Delta_2\\,\\big(\\tfrac{\\mathrm d r[i-1]}{\\Delta_1} + \\tfrac{\\mathrm d r[i+1]}{\\Delta_3}\\big) \\big\\rvert.\\) - If the total is below the threshold, node i is erasable; otherwise it is kept.</p> </li> </ul> <p>Index reconstruction and derivative scaling: - Build the kept index list <code>inds</code> including \\(0\\) and \\(N-1\\). - Build <code>indsD</code> by shifting interior kept indices by \\(+1\\) for derivative\u2011anchored data; set <code>indsD[0]=0</code>. - Compute <code>tfac</code> per kept chunk: <code>tfac[0]=1</code>, and for <code>i &gt; 0</code></p> <p>$$ \\displaystyle \\text{tfac}[i] = \\frac{t\\big[\\text{inds}[i]\\big] - t\\big[\\text{inds}[i-1]\\big]}{t\\big[\\text{indsD}[i]\\big] - t\\big[\\text{indsD}[i]-1\\big]}. $$ - Gather arrays with these indices:     - QK, QR, r use <code>inds</code>.     - dQK, dQR, dr use <code>indsD</code> and are multiplied by tfac to preserve derivative consistency under grid compression. - Compress <code>t1grid</code> with <code>inds</code> and recompute \\(\\Delta t\\) and <code>delta_t_ratio</code> as \\(\\Delta t_i/\\Delta t_{i-1}\\) for \\(i \\ge 2\\).</p> <p>Cadence and modes: - The GPU implementation evaluates flags at even indices for efficiency; CPU checks all interior indices. - Aggressive vs conservative modes only change the threshold value and sweep cadence; the mechanism is identical. - After sparsification, the code may try SERK2 briefly; disable via <code>--serk2=false</code> if desired.</p> <p>Choosing a threshold: - Start from the default (tuned for len and \u03b5) and validate on short runs by comparing C and R slices and derived observables (energy, gFDR/FDT diagnostics) with sparsification off. Increase threshold for more compression; decrease for more accuracy.</p> <p>Implementation references: <code>include/sparsify/sparsify_utils.hpp</code>, <code>src/sparsify/sparsify_utils.cpp</code> (CPU), <code>src/sparsify/sparsify_utils.cu</code> (GPU). Post\u2011prune, interpolation is re\u2011initialized automatically by downstream calls.</p>"},{"location":"concepts/time-integration/","title":"Time integration","text":"<p>Default strategy: adaptive Dormand\u2013Prince RK54. When the adaptive step approaches the RK54 stability limit, the solver switches to SSPRK(10,4) for stability at larger steps. After each sparsification event, the code may attempt SERK2; this trial can be disabled via CLI.</p> <p>Summary: - RK54 = Dormand\u2013Prince (adaptive default): embedded error estimate controls local error and proposes \u0394t. - SSPRK(10,4) (auto\u2011switch): engaged when RK54 reaches its absolute\u2011stability bound to continue with stable steps at late times. - SERK2 (optional): attempted after sparsification to exploit extended stability; can be turned off with a command\u2011line flag.</p> <p>Error and stability controls (paper supplemental and code): - Error bound on each step applies to the 1\u2011norm of C and R:</p> \\[ \\|C(t,\\, \\phi_k\\, t)\\|_1 + \\|R(t,\\, \\phi_k\\, t)\\|_1 \\leq \\varepsilon. \\] <ul> <li>Dormand\u2013Prince stability along the negative real axis extends to about \\(-3.307\\). With an upper bound on the Jacobian spectral radius \\(\\lambda_{\\max} \\lesssim 4\\,\\Sigma''(1)\\), the code switches to SSPRK\\((10,4)\\) once \\(\\lambda_{\\max}\\,\\Delta t \\gtrsim 3.0\\). On switch, \\(\\Delta t\\) is halved once to account for the lower order, then adapted normally.</li> <li>Step\u2011size controller increases \\(\\Delta t\\) slightly when below target error and reduces it when above (simple proportional strategy; details in supplemental text).</li> </ul> <p>CLI controls: - <code>-e</code> error tolerance (\u03b5) for the embedded estimate. - <code>-d</code> minimum time step to avoid over\u2011refinement near initial transients. - <code>-m</code>, <code>-t</code> cap total iterations and physical time. - <code>--serk2=true|false</code> enables/disables SERK2 trials after sparsification.</p> <p>Practice: - Check step\u2011size independence of key observables (C, R) at representative times. - If SERK2 trials are disabled, expect exclusively Dormand\u2013Prince and SSPRK\\((10,4)\\).</p> <p>Implementation details: see <code>include/EOMs/</code> and <code>src/EOMs/</code> (RK54 Dormand\u2013Prince, SSPRK(10,4), SERK2 kernels and selection logic).</p>"},{"location":"concepts/version-compatibility/","title":"Version compatibility","text":"<p>Outputs embed build/version metadata. Resume compatibility is determined by the version policy and can be overridden explicitly.</p> <p>Policy: - Identical: code_version in file equals current code_version \u2192 resume allowed silently. - Compatible: major.minor match (first two numeric parts equal) \u2192 resume allowed; warnings may be emitted if git branch/hash differ. - Warning: file version unknown or partial metadata \u2192 resume allowed with a warning. - Incompatible: major.minor differ \u2192 resume aborted unless <code>--allow-incompatible-versions=true</code> is set.</p> <p>Behavior and sources: - Version info sources: <code>include/version/version_info.hpp</code> and <code>src/version/version_info.cpp</code> (code_version, git hash/branch, compiler, CUDA/OpenMP flags). - Checks and reporting: <code>src/version/version_compat.cpp</code> (functions: analyzeVersionCompatibility, checkVersionCompatibilityInteractive/basic), used during config parsing and when resuming. - CLI shortcuts: <code>-c, --check FILE</code> prints an analysis for a <code>params.txt</code> without running; <code>--allow-incompatible-versions=true|false</code> toggles override.</p> <p>What is compared when resuming: - Primarily the code version string. Additional metadata (git branch/hash, dirty state) are reported as warnings when major.minor are equal but commits differ. - Runtime options like <code>--serk2</code> and sparsification aggressiveness are stored with outputs and re\u2011applied; mismatches are surfaced in logs even if allowed.</p> <p>Recommendation: - Prefer resuming only with compatible versions. If you must override, record the exact git hash and re\u2011validate observables (energy, equal\u2011time C, representative C(t, \u03b1t)).</p>"},{"location":"dev/contributing/","title":"Contributing","text":"<p>Thanks for your interest in contributing to DMFE!</p>"},{"location":"dev/contributing/#workflow","title":"Workflow","text":"<ul> <li>Fork and create a feature branch</li> <li>Keep changes focused; add or update docs when public behavior changes</li> <li>Open a PR with a clear summary and testing evidence</li> </ul>"},{"location":"dev/contributing/#code-style","title":"Code style","text":"<ul> <li>C++17, consistent formatting (clang-format if config exists)</li> <li>Doxygen comments for public APIs</li> <li>Keep lines \u2264 100 chars; prefer small, focused headers and source files</li> </ul>"},{"location":"dev/contributing/#testing","title":"Testing","text":"<ul> <li>Perform a short run (CPU is fine) and include key metrics/logs</li> <li>For changes to outputs, document the effect in <code>docs/usage.md</code></li> </ul>"},{"location":"dev/contributing/#docs","title":"Docs","text":"<ul> <li>Update or add pages under <code>docs/</code> (how-tos, concepts, tutorials)</li> <li>Run <code>./docs/gen_api.sh</code> if you changed public headers</li> </ul>"},{"location":"dev/release/","title":"Release Process","text":"<p>1) Update <code>CHANGELOG.md</code> (Keep a Changelog format) 2) Bump version macros or metadata in <code>include/version/*</code> 3) Ensure docs build (MkDocs + Doxygen) is green 4) Tag the release <code>vW.X.Y.Z</code> 5) Publish release notes with key changes and upgrade notes</p>"},{"location":"dev/testing/","title":"Testing","text":"<p>Lightweight validation strategy:</p> <ul> <li>Build and run a short CPU test to ensure basic correctness</li> <li>Use <code>RegressionRuns/</code> to compare outputs between branches</li> <li>Verify CLI help (<code>-h</code>) matches docs after option changes</li> </ul> <p>Future work: - Add scripted sanity tests that parse small outputs and compare invariants</p>"},{"location":"howto/add-new-io-format/","title":"How-to: Add a New IO Format","text":"<p>1) Extend <code>src/io/</code> with a writer/reader for the new format. 2) Integrate with existing async export flow (respect <code>--async-export</code>). 3) Add CLI flag(s) to select the format if needed. 4) Update <code>usage.md</code> and <code>reading-outputs.md</code>. 5) Provide a small example file and reader snippet for users.</p>"},{"location":"howto/add-new-kernel/","title":"How-to: Add a New Kernel","text":"<p>1) Start with a header in <code>include/</code> and CPU path <code>.cpp</code> in <code>src/</code>. 2) Add a CUDA path <code>.cu</code> in <code>src/</code> guarded by <code>DMFE_WITH_CUDA</code>. 3) Register files in <code>CMakeLists.txt</code> under CPU_SOURCES and GPU_SOURCES. 4) Ensure host/device utilities (<code>include/core/*</code>) are used consistently. 5) Benchmark on a small grid; add a tutorial snippet if useful.</p>"},{"location":"howto/add-new-observable/","title":"How-to: Add a New Observable","text":"<p>1) Define data structure in <code>include/simulation/simulation_data.hpp</code> (or suitable module). 2) Compute it in the time step (SERK2/RK) or post-step hook. 3) Export: extend IO (<code>src/io/io_output.*</code>) to write it to HDF5/bin and text. 4) Document: update <code>docs/usage.md</code> and list in outputs. 5) Test: add a short run and check values/logs.</p>"},{"location":"reference/","title":"Reference","text":"<p>API documentation is auto-generated and currently excluded from the site build to avoid broken links. Once the API generator emits consistent relative links, re-enable it by removing the exclude plugin entries for <code>reference/api/**</code> and <code>reference/doxygen/**</code> in <code>mkdocs.yml</code> and adding the desired landing pages back to the nav.</p>"},{"location":"tutorials/cluster-portable-build/","title":"Tutorial: Cluster Portable Build","text":"<p>Build and run on heterogeneous cluster nodes without <code>-march=native</code> and with shared cudart.</p> <p>Configure:</p> <pre><code>cmake -S . -B build -DDMFE_PORTABLE_BUILD=ON -DCMAKE_CUDA_ARCHITECTURES=80\ncmake --build build -j $(nproc)\n</code></pre> <p>Run:</p> <pre><code>./RG-Evo -L 1024 -l 0.5\n</code></pre> <p>Tips: - Pick the lowest common SM (e.g., 80 for A100). - For CPU-only environments, set <code>-DDMFE_WITH_CUDA=OFF</code>.</p>"},{"location":"tutorials/cpu-only/","title":"Tutorial: CPU-only Run","text":"<p>If CUDA is not available or you want deterministic CPU runs, disable the GPU path.</p> <p>Build as usual, then run:</p> <pre><code>./RG-Evo --gpu false -L 512 -l 0.5 -m 20000\n</code></pre> <p>Notes: - CPU fallback is always available. - Performance is lower than GPU; reduce <code>-m</code> or <code>-t</code> for quick experiments.</p>"},{"location":"tutorials/first-run/","title":"Tutorial: First Run","text":"<p>Goal: build and run DMFE in Release on L=512 grid and inspect outputs.</p> <p>1) Build: <pre><code>./build.sh\n</code></pre> 2) Run a short simulation: <pre><code>./RG-Evo -m 20000 -L 512 -l 0.5 -D false\n</code></pre> 3) Inspect outputs: - Explore the output directory printed at start - Open <code>params.txt</code> for parameters and environment - If HDF5 was available, inspect <code>data.h5</code> (e.g., with h5ls/h5dump)</p> <p>Troubleshooting: - Missing <code>Grid_data/512</code>: pick another <code>-L</code> with existing data (512/1024/2048) - GPU errors: retry with <code>--gpu false</code></p>"},{"location":"tutorials/parameter-sweep/","title":"Tutorial: Parameter Sweep","text":"<p>Run a simple sweep over <code>lambda</code> while reusing grid data.</p> <p>Example shell loop:</p> <pre><code>for L in 512; do\n  for lam in 0.4 0.5 0.6; do\n    ./RG-Evo -L \"$L\" -l \"$lam\" -m 40000 -D false -s true \\\n      --out-dir \"Results/sweep_L${L}\"\n  done\ndone\n</code></pre> <p>Outputs are organized under your chosen out-dir by parameter tuple.</p>"},{"location":"tutorials/reading-outputs/","title":"Tutorial: Reading Outputs","text":"<p>DMFE writes either HDF5 (<code>data.h5</code>) or binary (<code>data.bin</code>) plus text summaries.</p> <ul> <li>HDF5 datasets: <code>QKv</code>, <code>QRv</code>, <code>dQKv</code>, <code>dQRv</code>, <code>t1grid</code>, <code>rvec</code>, <code>drvec</code></li> <li>Attributes: parameters, time, iteration, version info</li> </ul> <p>Inspect with common tools:</p> <pre><code>h5ls -r data.h5\nh5dump -n data.h5\n</code></pre> <p>Binary fallback: - See <code>include/io/io_utils.hpp</code> for formats; use provided helper readers (planned) or convert with a small script.</p>"}]}